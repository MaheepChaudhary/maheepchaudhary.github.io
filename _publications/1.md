---
title: "Causal abstraction for faithful model interpretation"
collection: publications
permalink: /publication/1
excerpt: 'The importance of trustworthy machine learning is a critical topic, covering robustness, security, interpretability, and fairness. Over the last decade, various methods have emerged to address these challenges. This survey systematically reviews advancements from a data centric perspective, emphasizing the limitations of traditional empirical risk minimization (ERM) in handling data related challenges. Interestingly, despite developing independently, these methods across trustworthy machine learning converge, with Pearl causality hierarchy providing a unifying framework. The survey presents a unified language and mathematical vocabulary, connecting methods in robustness, adversarial robustness, interpretability, and fairness. This approach fosters a cohesive understanding of the field. The survey also explores the trustworthiness of large pretrained models, connecting techniques like fine tuning, parameter efficient fine tuning, prompting, and reinforcement learning with human feedback to standard ERM. This connection extends the principled understanding of trustworthy methods to these models, laying the groundwork for future approaches. The survey reviews existing methods and concludes with a summary of applications and potential future aspects. For more information, please visit http://trustai.one.'
date: 2024/8/07
venue: 'Arxiv as Pre-Print'
paperurl: 'https://arxiv.org/pdf/2301.04709'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
<!-- This paper is about the number 1. The number 2 is left for future work. -->

[Download paper here](https://arxiv.org/pdf/2301.04709)

<!-- Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->
