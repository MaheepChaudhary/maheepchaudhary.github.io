---
title: "Causal abstraction for faithful model interpretation"
collection: publications
permalink: /publication/2024-10-01-paper-title-number-1
excerpt: 'Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field con- cerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) provid- ing a flexible, yet precise formalization for the core concepts of modular features, polysemantic neurons, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability method- ologies in the common language of causal abstraction, namely activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse au- toencoders, differential binary masking, distributed alignment search, and activation steering.'
date: 2024/8/07
venue: 'Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, Thomas Icard'
paperurl: 'https://arxiv.org/pdf/2301.04709'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
<!-- This paper is about the number 1. The number 2 is left for future work. -->

[Download paper here](https://arxiv.org/pdf/2301.04709)

<!-- Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->
